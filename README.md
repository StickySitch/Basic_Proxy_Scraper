# Basic_Proxy_Scraper
## Resources
`Dependencies:` [proxy-checker](https://pypi.org/project/proxy-checker/) **|** [pyfiglet](https://pypi.org/project/pyfiglet/) **|** [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) **|** [requests](https://docs.python-requests.org/en/latest/) **|** [re (Regex)](https://docs.python.org/3/library/re.html)
`Source Code:` [BasicProxyScraper.py](https://github.com/StickySitch/Basic_Proxy_Scraper/blob/main/BasicProxyScraper.py "BasicProxyScraper.py")

## Output
The output for all proxies will be through text files and be put into the initialized directories.

Files beginning with "All" are the unchecked (all) proxy outputs. This file will populate even if you select to not use the `proxy-checker`.


## Simple Use Example

### Step 1:
Run the scraper in terminal or through your IDE. 
Using CMD and your choice of terminal, navigate to the directory housing the `BasicProxyScraper.py` and type `python BasicProxyScraper.py`. You will see something similar to the image below after hitting enter. Answer if you would like to have your proxies checked with either "Yes" or "No"
![Step One](https://github.com/StickySitch/Basic_Proxy_Scraper/blob/main/README%20Images/5ecWaqf.png)

### Step 2:
The next question will be about about the amount of threads you would like to run. This will depend of your PC's available power so you may have to fiddle and find the number for you. I usually choose 200-300.
![Step 2](https://github.com/StickySitch/Basic_Proxy_Scraper/blob/main/README%20Images/nWqNRK6.png)

### Step 3:
Last step is to let it run! Sit back and wait for it to finish. Once done, your proxies will be within the output text files.
![Step 3](https://github.com/StickySitch/Basic_Proxy_Scraper/blob/main/README%20Images/dj9CHRs.png)

